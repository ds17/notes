{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6.5 color='blue'>Discovering Groups</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogdata=pd.read_table('blogdata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分级聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readflie(filename):\n",
    "    file = open(filename,'r')\n",
    "    lines = [line for line in file]\n",
    "    \n",
    "    colnames=lines[0].strip().split('\\t')[1:]\n",
    "    rownames=[]\n",
    "    data=[]\n",
    "    for line in lines[1:]:\n",
    "        p = line.strip().split('\\t')\n",
    "        rownames.append(p[0])\n",
    "        data.append([float(x) for x in p[1:]])\n",
    "    return rownames,colnames,data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "紧密度计算\n",
    "- `1-pearsonr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math import sqrt\n",
    "# def pearson(v1,v2):\n",
    "#     sum1=sum(v1)\n",
    "#     sum2=sum(v2)\n",
    "    \n",
    "#     sum1sq=sum([pow(x,2) for x in v1])\n",
    "#     sum2sq=sum([pow(x,2) for x in v2])\n",
    "    \n",
    "#     psum= sum([v1[i]*v2[i] for i in range(len(v1))])\n",
    "    \n",
    "#     num=psum-(sum1*sum2/len(v1))\n",
    "#     den = den=sqrt((sum1Sq-pow(sum1,2)/len(v1))*(sum2Sq-pow(sum2,2)/len(v1)))\n",
    "#     if den==0: return 0\n",
    "    \n",
    "#     return 1.0-num/den\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "def pearson(v1,v2):\n",
    "    r,p_value = pearsonr(v1,v2)\n",
    "    if p_value==1: r=0\n",
    "    return 1.0 - r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class bicluster:\n",
    "    def __init__(self,vec,left=None,right=None,distance=0.0, i_d=None):\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.vec=vec\n",
    "        self.i_d=i_d\n",
    "        self.distance = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blognames,words,data=readflie('blogdata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hcluster(rows,distance=pearson):\n",
    "    distances={}\n",
    "    currentclustid=-1\n",
    "    \n",
    "    clust = [bicluster(rows[i],i_d=i) for i in range(len(rows))]\n",
    "    \n",
    "    while len(clust)>1:\n",
    "        lowestpair = (0,1)\n",
    "        closest=distance(clust[0].vec, clust[1].vec)\n",
    "\n",
    "        for i in range(len(clust)):\n",
    "            for j in range(i+1,len(clust)):\n",
    "                if (clust[i].i_d,clust[j].i_d) not in distances:\n",
    "                    distances[(clust[i].i_d,clust[j].i_d)]=distance(clust[i].vec,clust[j].vec)\n",
    "                d = distances[(clust[i].i_d,clust[j].i_d)]\n",
    "\n",
    "                if d<closest:\n",
    "                    closest=d\n",
    "                    lowestpair=(i,j)\n",
    "        mergevec=[\n",
    "            (clust[lowestpair[0]].vec[i] + clust[lowestpair[1]].vec[i]) /2.0 \n",
    "            for i in range(len(clust[0].vec))]\n",
    "\n",
    "        newcluster = bicluster(mergevec,left=clust[lowestpair[0]], right=clust[lowestpair[1]],distance=closest, i_d=currentclustid)   \n",
    "        #构件新的 bicluster 对象，并将上级两个 bicluster 元素写入 left/right属性\n",
    "\n",
    "        currentclustid-=1\n",
    "        del clust[lowestpair[1]]  #先删除大序号，再删除小序号，否则序号会乱\n",
    "        del clust[lowestpair[0]]\n",
    "        clust.append(newcluster)  #i_d为负数，且放在clust最后\n",
    "    \n",
    "    return clust[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clust = hcluster(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printclust(clust,labels=None, n=0):\n",
    "    for i in range(n):\n",
    "        print(' ',end='')\n",
    "    if clust.i_d<0:\n",
    "        print('-')\n",
    "    else:\n",
    "        if labels==None: print(clust.i_d)\n",
    "        else: print(labels[clust.i_d])     \n",
    "    \n",
    "    #递归搜索        \n",
    "    if clust.left!=None: printclust(clust.left,labels=labels, n=n+1)\n",
    "    if clust.right!=None: printclust(clust.right,labels=labels, n=n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      " gapingvoid: \"cartoons drawn on the back of business cards\"\n",
      " -\n",
      "  -\n",
      "   Schneier on Security\n",
      "   Instapundit.com\n",
      "  -\n",
      "   The Blotter\n",
      "   -\n",
      "    -\n",
      "     MetaFilter\n",
      "     -\n",
      "      SpikedHumor\n",
      "      -\n",
      "       Captain's Quarters\n",
      "       -\n",
      "        Michelle Malkin\n",
      "        -\n",
      "         -\n",
      "          NewsBusters.org - Exposing Liberal Media Bias\n",
      "          -\n",
      "           -\n",
      "            Hot Air\n",
      "            Crooks and Liars\n",
      "           -\n",
      "            Power Line\n",
      "            Think Progress\n",
      "         -\n",
      "          Andrew Sullivan | The Daily Dish\n",
      "          -\n",
      "           Little Green Footballs\n",
      "           -\n",
      "            Eschaton\n",
      "            -\n",
      "             Talking Points Memo: by Joshua Micah Marshall\n",
      "             Daily Kos\n",
      "    -\n",
      "     43 Folders\n",
      "     -\n",
      "      TechEBlog\n",
      "      -\n",
      "       -\n",
      "        Mashable!\n",
      "        Signum sine tinnitu--by Guy Kawasaki\n",
      "       -\n",
      "        -\n",
      "         -\n",
      "          Slashdot\n",
      "          -\n",
      "           MAKE Magazine\n",
      "           Boing Boing\n",
      "         -\n",
      "          -\n",
      "           Oilman\n",
      "           -\n",
      "            Online Marketing Report\n",
      "            -\n",
      "             Treehugger\n",
      "             -\n",
      "              SimpleBits\n",
      "              -\n",
      "               Cool Hunting\n",
      "               -\n",
      "                Steve Pavlina's Personal Development Blog\n",
      "                -\n",
      "                 -\n",
      "                  ScienceBlogs : Combined Feed\n",
      "                  Pharyngula\n",
      "                 -\n",
      "                  BuzzMachine\n",
      "                  -\n",
      "                   Copyblogger\n",
      "                   -\n",
      "                    -\n",
      "                     The Viral Garden\n",
      "                     Seth's Blog\n",
      "                    -\n",
      "                     -\n",
      "                      Bloggers Blog: Blogging the Blogsphere\n",
      "                      -\n",
      "                       Sifry's Alerts\n",
      "                       ProBlogger Blog Tips\n",
      "                     -\n",
      "                      -\n",
      "                       Valleywag\n",
      "                       Scobleizer - Tech Geek Blogger\n",
      "                      -\n",
      "                       -\n",
      "                        O'Reilly Radar\n",
      "                        456 Berea Street\n",
      "                       -\n",
      "                        Lifehacker\n",
      "                        -\n",
      "                         Quick Online Tips\n",
      "                         -\n",
      "                          Publishing 2.0\n",
      "                          -\n",
      "                           Micro Persuasion\n",
      "                           -\n",
      "                            A Consuming Experience (full feed)\n",
      "                            -\n",
      "                             John Battelle's Searchblog\n",
      "                             -\n",
      "                              Search Engine Watch Blog\n",
      "                              -\n",
      "                               Read/WriteWeb\n",
      "                               -\n",
      "                                Official Google Blog\n",
      "                                -\n",
      "                                 Search Engine Roundtable\n",
      "                                 -\n",
      "                                  Google Operating System\n",
      "                                  Google Blogoscoped\n",
      "          -\n",
      "           -\n",
      "            -\n",
      "             -\n",
      "              Blog Maverick\n",
      "              -\n",
      "               Download Squad\n",
      "               -\n",
      "                CoolerHeads Prevail\n",
      "                -\n",
      "                 Joystiq\n",
      "                 The Unofficial Apple Weblog (TUAW)\n",
      "             -\n",
      "              Autoblog\n",
      "              -\n",
      "               Engadget\n",
      "               TMZ.com\n",
      "            -\n",
      "             Matt Cutts: Gadgets, Google, and SEO\n",
      "             -\n",
      "              PaulStamatiou.com\n",
      "              -\n",
      "               -\n",
      "                GigaOM\n",
      "                TechCrunch\n",
      "               -\n",
      "                -\n",
      "                 Techdirt\n",
      "                 Creating Passionate Users\n",
      "                -\n",
      "                 Joho the Blog\n",
      "                 -\n",
      "                  -\n",
      "                   PerezHilton.com\n",
      "                   Jeremy Zawodny's blog\n",
      "                  -\n",
      "                   Joi Ito's Web\n",
      "                   -\n",
      "                    ongoing\n",
      "                    -\n",
      "                     Joel on Software\n",
      "                     -\n",
      "                      -\n",
      "                       we make money not art\n",
      "                       -\n",
      "                        plasticbag.org\n",
      "                        -\n",
      "                         Signal vs. Noise\n",
      "                         -\n",
      "                          kottke.org\n",
      "                          -\n",
      "                           Neil Gaiman's Journal\n",
      "                           -\n",
      "                            -\n",
      "                             The Huffington Post | Raw Feed\n",
      "                             -\n",
      "                              Wonkette\n",
      "                              -\n",
      "                               Gawker\n",
      "                               -\n",
      "                                The Superficial - Because You're Ugly\n",
      "                                Go Fug Yourself\n",
      "                            -\n",
      "                             Deadspin\n",
      "                             Gothamist\n",
      "                      -\n",
      "                       Kotaku\n",
      "                       Gizmodo\n",
      "           -\n",
      "            Shoemoney - Skills to pay the bills\n",
      "            -\n",
      "             flagrantdisregard\n",
      "             -\n",
      "              WWdN: In Exile\n",
      "              -\n",
      "               Derek Powazek\n",
      "               -\n",
      "                lifehack.org\n",
      "                Dave Shea's mezzoblue\n",
      "        -\n",
      "         Wired News: Top Stories\n",
      "         -\n",
      "          Topix.net Weblog\n",
      "          Bloglines | News\n"
     ]
    }
   ],
   "source": [
    "printclust(top_clust,labels=blognames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
